<p>OK，如果你还在为并发（concurrency）和并行（parallesim）这两个词的区别而感到困扰，那么这篇文章就是写给你看的。搞这种词语辨析到底有什么意义？其实没什么意义，但是有太多人在混用错用这两个词（比如遇到的某门课的老师）。不论中文圈还是英文圈，即使已经有数不清的文章在讨论并行vs并发，却极少有能讲清楚的。让一个讲不清楚的人来解释，比不解释更可怕。比如我随便找了个网上的解释：</p>

<blockquote>
<p>前者是逻辑上的同时发生（simultaneous），而后者是物理上的同时发生．</p>

<p>并发性(concurrency)，又称共行性，是指能处理多个同时性活动的能力，并发事件之间不一定要同一时刻发生。</p>

<p>并行(parallelism)是指同时发生的两个并发事件，具有并发的含义，而并发则不一定并行。</p>

<p>来个比喻：并发和并行的区别就是一个人同时吃三个馒头和三个人同时吃三个馒头。</p>
</blockquote>

<p>看了之后，你懂了么？不懂，更晕了。写出这类解释的人，自己也是一知半解，却又把自己脑子里模糊的影像拿出来写成文章，让读者阅毕反而更加疑惑。当然也有可能他确实懂了，但是写出这种文字也不能算负责。至于本文，请相信，一定是准确的，我也尽量做到讲解清晰。</p>

<p>OK，下面进入正题，<strong>concurrency vs parallesim</strong></p>

<p>让我们大声朗读下面这句话：</p>

<h2>
<a id="user-content-并发指的是程序的结构并行指的是程序运行时的状态" class="anchor" href="#%E5%B9%B6%E5%8F%91%E6%8C%87%E7%9A%84%E6%98%AF%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%BB%93%E6%9E%84%E5%B9%B6%E8%A1%8C%E6%8C%87%E7%9A%84%E6%98%AF%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%8A%B6%E6%80%81" aria-hidden="true"><span class="octicon octicon-link"></span></a>“并发”指的是程序的结构，“并行”指的是程序运行时的状态</h2>

<p>即使不看详细解释，也请记住这句话。下面来具体说说：</p>

<h3>
<a id="user-content-并行parallesim" class="anchor" href="#%E5%B9%B6%E8%A1%8Cparallesim" aria-hidden="true"><span class="octicon octicon-link"></span></a>并行（parallesim）</h3>

<p>这个概念很好理解。所谓并行，就是<strong>同时执行</strong>的意思，无需过度解读。判断程序是否处于并行的<strong>状态</strong>，就看同一时刻是否有超过一个“工作单位”在运行就好了。所以，<strong>单线程永远无法达到并行状态</strong>。</p>

<p>要达到并行状态，最简单的就是利用多线程和多进程。但是Python的多线程由于存在著名的GIL，无法让两个线程真正“同时运行”，所以实际上是无法到达并行状态的。</p>

<h3>
<a id="user-content-并发concurrency" class="anchor" href="#%E5%B9%B6%E5%8F%91concurrency" aria-hidden="true"><span class="octicon octicon-link"></span></a>并发（concurrency）</h3>

<p>要理解“并发”这个概念，必须得清楚，<strong>并发指的是程序的“结构”</strong>。当我们说这个程序是并发的，实际上，这句话应当表述成“这个程序采用了支持并发的设计”。好，既然并发指的是人为设计的结构，那么怎样的程序结构才叫做支持并发的设计？</p>

<p><strong>正确的并发设计的标准是：使多个操作可以在重叠的时间段内进行(two tasks can start, run, and complete in overlapping time periods)</strong>。</p>

<p>这句话的重点有两个。我们先看“（操作）在重叠的时间段内进行”这个概念。它是否就是我们前面说到的并行呢？是，也不是。并行，当然是在重叠的时间段内执行，但是另外一种执行模式，也属于在重叠时间段内进行。这就是<a href="http://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B">协程</a>。</p>

<p>使用协程时，程序的执行看起来往往是这个样子：</p>

<p><a href="/media/content/BlogPost/images/coroutine.jpg" target="_blank"><img src="/media/content/BlogPost/images/coroutine.jpg" alt="" style="max-width:100%;"></a></p>

<p>task1、task2是两段不同的代码，比如两个函数，其中黑色块代表某段代码正在执行。注意，这里从始至终，<strong>在任何一个时间点上都只有一段代码在执行</strong>，但是，由于task1和task2在重叠的时间段内执行，所以这是一个支持并发的设计。与并行不同，单核单线程能支持并发。</p>

<p>经常看到这样一个说法，叫做<strong>并发执行</strong>。现在我们可以正确理解它。有两种可能：</p>

<ol>
<li>原本想说的是“并行执行”，但是用错了词</li>
<li>指多个操作可以在重叠的时间段内进行，即，真的并行，或是类似上图那样的执行模式。</li>
</ol>

<p>我的建议是尽可能不使用这个词，容易造成误会，尤其是对那些并发并行不分的人。但是读到这里的各位显然能正确区分，所以下面为了简便，将使用并发执行这个词。</p>

<p>第二个重点是“<strong>可以</strong>在重叠的时间段内进行”中的“可以”两个字。“可以”的意思是，正确的并发设计使并发执行成为可能，但是程序在实际运行时却不一定会出现多个任务执行时间段overlap的情形。比如：我们的程序会为每个任务开一个线程或者协程，只有一个任务时，显然不会出现多个任务执行时间段重叠的情况，有多个任务时，就会出现了。这里我们看到，并发并不描述程序执行的状态，它描述的是一种设计，是程序的结构，比如上面例子里“为每个任务开一个线程”的设计。并发设计和程序实际执行情况没有直接关联，但是正确的并发设计让并发执行成为可能。反之，如果程序被设计为执行完一个任务再接着执行下一个，那就不是并发设计了，因为做不到并发执行。</p>

<p>那么，如何实现支持并发的设计？两个字：<strong>拆分</strong>。</p>

<p>之所以并发设计往往需要把流程拆开，是因为如果不拆分也就不可能在同一时间段进行多个任务了。这种拆分可以是平行的拆分，比如抽象成同类的任务，也可以是不平行的，比如分为多个步骤。</p>

<h3>
<a id="user-content-并发和并行的关系" class="anchor" href="#%E5%B9%B6%E5%8F%91%E5%92%8C%E5%B9%B6%E8%A1%8C%E7%9A%84%E5%85%B3%E7%B3%BB" aria-hidden="true"><span class="octicon octicon-link"></span></a>并发和并行的关系</h3>

<blockquote>
<p><strong>Different concurrent designs enable different ways to parallelize.</strong></p>
</blockquote>

<p>这句话来自著名的talk: <a href="http://blog.golang.org/concurrency-is-not-parallelism"><strong>Concurrency is not parallelism</strong></a>。它足够concise，以至于不需要过多解释。但是仅仅引用别人的话总是不太好，所以我再用之前文字的总结来说明：<strong>并发设计让并发执行成为可能，而并行是并发执行的一种模式</strong>。</p>

<p>最后，关于Concurrency is not parallelism这个talk再多说点。自从这个talk出来，直接引爆了一堆讨论并发vs并行的文章，并且无一例外提到这个talk，甚至有的文章直接用它的slide里的图片来说明。比如这张：</p>

<p><a href="/media/content/BlogPost/images/gophercomplex0.jpg" target="_blank"><img src="/media/content/BlogPost/images/gophercomplex0.jpg" alt="" style="max-width:100%;"></a></p>

<p>以为我要解释这张图吗？NO。放这张图的唯一原因就是萌萌的gopher。</p>

<p>再来张特写：</p>

<p><a href="/media/content/BlogPost/images/gopher.png" target="_blank"><img src="/media/content/BlogPost/images/gopher.png" alt="" style="max-width:100%;"></a></p>

<p>之前看到知乎上有个关于go为什么流行的问题，有个答案是“logo萌”当时我就笑喷了。</p>

<p>好像跑题了，继续说这个talk。和很多人一样，我也是看了这个talk才开始思考concurrency vs parallesim的问题。为了研究那一堆推小车的gopher到底是怎么回事，我花费了相当多的时间。实际上后来我更多地是通过网上的只言片语（比如SO的回答）和自己的思考弄清了这个问题，talk并没有很大帮助。彻底明白之后再回过头来看这个talk，确实相当不错，Andrew Gerrand对这个问题的理解绝对够深刻，但是太不新手向了。最大问题在于，那一堆gopher的例子不够好，太复杂。Andrew Gerrand花了大把时间来讲述不同的并发设计，但是作为第一次接触这个话题的人，在没有搞清楚并发并行区别的情况下就去研究推小车的gopher，太难了。“Different concurrent designs enable different ways to parallelize”这句总结很精辟，但也只有那些已经透彻理解的人才能领会，比如我和看到这里的读者，对新手来说就和经文一样难懂。总结下来一句话，不要一开始就去看这个视频，也不要花时间研究推小车的gopher。<strong>Gopher is moe, but confusing</strong>.</p>
